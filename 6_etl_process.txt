Для подсчета наиболее и наименее счастливой страны/локации/пользователя необходимо вычислять средний tweet_sentiment их твитов и найти среди них максимум и минимум. Для того чтобы не пересчитывать каждый раз среднее по всему набору данных можно сохранять сумму и число твитов:
	User (id, sentiment_sum, tweet_count)
	Location (id, sentiment_sum, tweet_count)
	Country (code, sentiment_sum, tweet_count)
	Leader (category, sentiment, link)
(это можно как в базе, так и в памяти)

Тогда можно избежать хранения миллионов твитов и обрабатывать их потоково, а занимаемый объем можно оценить так:
	число пользователей < числа твитов
	локаций << твитов
	стран ~ 250
	лидеры – 6 значений

Статистика подсчитывается следующим образом:
Для каждого твита из tweet.json:
	Вычисляем tweet_sentiment
	Новый sentiment пользователя = (sentiment_sum + tweet_sentiment) / (tweet_count + 1)
	Обновляем sentiment_sum, tweet_count
	Сравниваем с таблицей лидеров, если sentiment больше/меньше рекордного – сохраняем новый рекорд и ссылку на пользователя.
	Аналогично для локации, страны
Затем сохраняем Leader в выходной файл на FTP.
При наступлении нового дня таблицы очищаются, либо храним еще и дату.
Получается линейная сложная алгоритма (если считать что вставка в таблицу – O(1)). 
Можно хранить  не sentiment_sum, а sentiment_avg, но тогда возможна ошибка накопления.